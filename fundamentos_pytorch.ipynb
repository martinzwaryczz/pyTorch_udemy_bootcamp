{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd2296c",
   "metadata": {},
   "source": [
    "# Fundamentos de pyTorch\n",
    "\n",
    "En este archivo estarán contemplados los conceptos introducctorios al framework: sus estructuras básicas, propiedades y funciones junto a su marco teórico.\n",
    "\n",
    "Gran parte del material fue sacado del bootcamp y esta en el siguiente sitio: https://www.learnpytorch.io/\n",
    "\n",
    "<center><img src=\"img/bootcamp.png\" alt=\"Bootcamp\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b93db1ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.1+cpu\n"
     ]
    }
   ],
   "source": [
    "# Importamos la libreria y visualizaremos su versión\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ee31054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otras librerias a utilizar\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de9b4d7d",
   "metadata": {},
   "source": [
    "# Tensores\n",
    "\n",
    "Los tensores son una estructura de datos muy eficiente para almacenar grandes volumenes de información dado que son estructuras N dimensionales de NxNxN dimensiones siendo N >=0.\n",
    "Si bien esta definición no es para nada estrictamente matemática, como informáticos podrémos valernos de esta para entender con que estáremos trabajando. \n",
    "\n",
    "<center><img src=\"img/tensor.png\" alt=\"Bootcamp\" width=\"500\"></center>\n",
    "\n",
    "PyTorch trata a los tensores mediante vectores de numpy. \n",
    "\n",
    "Es imposible acordarse de memoria todos los tipos y propiedades de los tensores, es por esto que nunca esta demás tener presente la documentación oficial de pyTorch: https://docs.pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e11662e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: 7\n",
      "Dimensión: 0\n",
      "Valor de un tensor de un solo elemento: <built-in method item of Tensor object at 0x000002498DDEB390>\n"
     ]
    }
   ],
   "source": [
    "# Tensor escalar junto a algunas funciones y propiedades\n",
    "\n",
    "scalar = torch.tensor(7)\n",
    "\n",
    "print(f\"Tensor: {scalar}\")\n",
    "print(f\"Dimensión: {scalar.ndim}\")\n",
    "print(f\"Valor de un tensor de un solo elemento: {scalar.item}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf3fa4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector: tensor([7, 7])\n",
      "Tamaño del vector contenido: torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "# Tensor vector junto a algunas funciones y propiedades\n",
    "# Recordar que los vectores en Python son en realidad listas\n",
    "\n",
    "vector = torch.tensor([7,7])\n",
    "vector\n",
    "\n",
    "print(f\"Vector: {vector}\")\n",
    "print(f\"Tamaño del vector contenido: {vector.shape}\") # Forma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3201783c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz: tensor([[ 7,  8],\n",
      "        [ 9, 10]])\n",
      "Dimensión de la matriz: 2\n",
      "Forma u orden de la matriz: torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "# Matrices\n",
    "\n",
    "matriz = torch.tensor([[7,8],\n",
    "                       [9, 10]])\n",
    "\n",
    "print(f\"Matriz: {matriz}\")  \n",
    "print(f\"Dimensión de la matriz: {matriz.ndim}\")\n",
    "print(f\"Forma u orden de la matriz: {matriz.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b318fd68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor:\n",
      "tensor([[[ 1,  2,  3],\n",
      "         [ 5,  4,  1],\n",
      "         [10,  0, -1]]])\n",
      "Dimensión del tensor: 3\n",
      "Tamaño u orden del tensor: torch.Size([1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "# Tensores\n",
    "\n",
    "tensor = torch.tensor([[[1, 2, 3],\n",
    "                        [5, 4, 1],\n",
    "                        [10, 0, -1]]])\n",
    "\n",
    "print(\"Tensor:\")\n",
    "print(f\"{tensor}\")\n",
    "print(f\"Dimensión del tensor: {tensor.ndim}\")\n",
    "print(f\"Tamaño u orden del tensor: {tensor.shape}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaa7ef1",
   "metadata": {},
   "source": [
    "# Dimensión de los tensores\n",
    "\n",
    "Para analizar el orden de los tensores en un código que es plano, en donde no podemos ver directamente los tensores como si fueran un \"cubo rubik\" debemos analizar la cantidad de elementos entre corchetes creados.\n",
    "La función tensor.shape no falla, está en nosotros comprender el funcionamiento de esta y los tensores como estructuras lógicas que almacenan los datos en cuestión, sean del tipo que sean."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a931fe2a",
   "metadata": {},
   "source": [
    "# Tensores con valores aleatorios\n",
    "\n",
    "Las redes neuronales no tienen manera de saber que valores ingresarán en su capa de entrada, por lo que una forma de simular estas posibles estructuras es crear tensores con valores aleratorios comprendidos en un determinado dominio especificado en la función rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e7ac970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor random: \n",
      "tensor([[0.0065, 0.2001, 0.4700, 0.1892],\n",
      "        [0.8559, 0.3059, 0.8484, 0.6446],\n",
      "        [0.5072, 0.9482, 0.7944, 0.5032]])\n",
      "Dimensión del tensor: 2\n",
      "Orden del tensor: torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "tensor_random = torch.rand(3, 4) # Orden del tensor\n",
    "print(\"Tensor random: \")\n",
    "print(f\"{tensor_random}\")\n",
    "print(f\"Dimensión del tensor: {tensor_random.ndim}\")\n",
    "print(f\"Orden del tensor: {tensor_random.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fee69b",
   "metadata": {},
   "source": [
    "# Tensor análogo al de procesamiento de imagenes de datasets de Kaggle de números, caras, entre otros.\n",
    "\n",
    "Estos tensores son de 224x224 y utilizan RGB (3 colores mezclados). \n",
    "Las fotos son infinitas, la combinación de colores también, y el tamaño el mismo dado que se trabaja con un set de datos especificamente preparado con fines educativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed4752a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orden del tensor: torch.Size([224, 224, 3])\n",
      "Dimensión del tensor: 3\n"
     ]
    }
   ],
   "source": [
    "random_image_size_tensor = torch.rand(size=(224, 224, 3)) # alto, ancho, colores(R,G,B) --> Esto puede estar en diferente orden, es decir: primero los colores y después el alto y ancho, o al revés. \n",
    "print(f\"Orden del tensor: {random_image_size_tensor.shape}\")\n",
    "print(f\"Dimensión del tensor: {random_image_size_tensor.ndim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff2ef58",
   "metadata": {},
   "source": [
    "# Tensor de 0 o 1\n",
    "\n",
    "Ideal para realizar filtros de tamaños asociados a tensores que pueden o no tener salidas validas según requerimientos.\n",
    "El tipo de dato (dtype) es float32  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db224d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_ceros = torch.zeros(size=(3,4))\n",
    "tensor_ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4f9c733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_unos = torch.ones(size=(3, 4))\n",
    "tensor_unos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed6ec1b",
   "metadata": {},
   "source": [
    "# Tensores con determinado rango y tamaño\n",
    "\n",
    "Con torch.arange() podrémos realizar tensores con tamaños, valores y saltos asociados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77c482e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 0 a 9: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "Tensor 1 a 10: tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "De 1 a 10 de 2 en 2: tensor([1, 3, 5, 7, 9])\n"
     ]
    }
   ],
   "source": [
    "cero_a_nueve = torch.arange(10)\n",
    "print(f\"Tensor 0 a 9: {cero_a_nueve}\")\n",
    "\n",
    "uno_a_diez = torch.arange(start=1, end=11)\n",
    "print(f\"Tensor 1 a 10: {uno_a_diez}\")\n",
    "\n",
    "con_pasos = torch.arange(start=1, end=10, step=2)\n",
    "print(f\"De 1 a 10 de 2 en 2: {con_pasos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30db6bc8",
   "metadata": {},
   "source": [
    "# Like: creará tensores iguales en estructura a otros pero con otros valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ac7d8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor 0: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "diez_ceros = torch.zeros_like(input=uno_a_diez)\n",
    "print(f\"Tensor 0: {diez_ceros}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ec8c8d",
   "metadata": {},
   "source": [
    "# Tipos de datos en tensores\n",
    "Debemos tener en cuenta determinadas propiedades de los tensores tales como:\n",
    "- Tipos de datos en tensores\n",
    "- Tamaño de los tensores\n",
    "- Propiedad DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88cd826a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_32_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=None, # TIPO DE DATO\n",
    "                               device=None, # CPU\n",
    "                               requires_grad=False) # NO TENGO IDEA\n",
    "float_32_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9d50bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6275, 0.8724, 0.4323, 0.9507],\n",
       "        [0.1394, 0.3529, 0.4208, 0.0805],\n",
       "        [0.3749, 0.9572, 0.0265, 0.4256]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor de prueba para probar las propiedades mencionadas arriba\n",
    "\n",
    "some_tensor = torch.rand(3, 4)\n",
    "some_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d836dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de data: torch.float32\n",
      "Orden del tensor: torch.Size([3, 4])\n",
      "Se va a ejecutar en: cpu\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tipo de data: {some_tensor.dtype}\")\n",
    "print(f\"Orden del tensor: {some_tensor.shape}\")\n",
    "print(f\"Se va a ejecutar en: {some_tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54ff1ef",
   "metadata": {},
   "source": [
    "# Operaciones con tensores\n",
    "\n",
    "Suma, resta, multiplicación, división"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ba7a6d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original: tensor([1, 2, 3])\n",
      "Tensor + 10: tensor([11, 12, 13])\n",
      "Tensor * 10: tensor([10, 20, 30])\n",
      "Tensor - 10: tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "# Craré entonces un tensor para realizar operaciones, estos son mutables: si realizamos una operación con estos cambiarán su estructura. \n",
    "\n",
    "tensor_operaciones = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(f\"Tensor original: {tensor_operaciones}\")\n",
    "print(f\"Tensor + 10: {tensor_operaciones + 10}\") # Sumará 10 a cada elemento del tensor en cuestión \n",
    "print(f\"Tensor * 10: {tensor_operaciones * 10}\") # Multplicará por 10 a cada elemento del tensor en cuestión\n",
    "print(f\"Tensor - 10: {tensor_operaciones - 10}\") # Restará 10 a cada elemento del tensor en cuestión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e40b345a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor + 10: tensor([11, 12, 13])\n",
      "Tensor * 10: tensor([10, 20, 30])\n",
      "Tensor - 10: tensor([-9, -8, -7])\n"
     ]
    }
   ],
   "source": [
    "# Esto puede hacerse con funciones que pyTorch nos proporciona:\n",
    "\n",
    "print(f\"Tensor + 10: {torch.add(tensor_operaciones, 10)}\")\n",
    "print(f\"Tensor * 10: {torch.mul(tensor_operaciones, 10)}\")\n",
    "print(f\"Tensor - 10: {torch.sub(tensor_operaciones, 10)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d905d",
   "metadata": {},
   "source": [
    "# Operaciones con matrices\n",
    "\n",
    "Las matices son pares ordenados que pueden ser sumados o multiplicados.\n",
    "En caso de tener una resta se cambiará el signo de la matriz con el signo adelante y se sumaran.\n",
    "Para que una matriz de orden *n.m* se pueda multiplicar por una *n.m* --> m = n\n",
    "\n",
    "<center><img src=\"img/mul_matrices.png\" alt=\"Bootcamp\" width=\"500\"></center>\n",
    "\n",
    "Cada fila deberá ser multiplicada por cada columna según el índice de la nueva matriz obtenida de orden *m.m*\n",
    "\n",
    "A su vez en ciertas ocasiones debemos usar la matiz transpuesta: esta invertirá las filas por columnas:\n",
    "\n",
    "<center><img src=\"img/matriz_transpuesta.png\" alt=\"m_transpuesta\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6893fe2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producto entre los elementos tensor([1, 4, 9])\n",
      "Producto matricial: 14\n"
     ]
    }
   ],
   "source": [
    "# Para el primer ejemplo usaré un tensor de orden 1,3 (1 fila, 3 columnas)\n",
    "\n",
    "tensor = torch.tensor([1,2,3]) # 1 * 1, 2 * 2, 3 * 3\n",
    "print(f\"Producto entre los elementos {tensor*tensor}\")\n",
    "\n",
    "# Esto sin embargo no es un producto de matrices: el orden de la matriz de retorno debería ser 1x1, para esto entonces usarémos torch.matmul(tensor, tensor)\n",
    "\n",
    "print(f\"Producto matricial: {torch.matmul(tensor, tensor)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9a8c17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ejemplo de multiplicación matricial de dos tensores:\n",
    "\n",
    "tensor_a = torch.tensor([[1, 2], [3, 4]])\n",
    "tensor_b = torch.tensor([[5, 6], [7, 8]])\n",
    "\n",
    "producto_matricial = torch.matmul(tensor_a, tensor_b)\n",
    "\n",
    "producto_matricial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "48226119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3],\n",
       "        [2, 4]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matriz transpuesta: tensor.T\n",
    "\n",
    "tensor_a.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dbc22cd",
   "metadata": {},
   "source": [
    "# Funciones de agregación en tensores\n",
    "\n",
    "Son similares a las de SQL: algunas de estas son min, max, mean, sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b734c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo: 0\n",
      "Maximo: 100\n",
      "Promedio: 50.0\n",
      "Suma de los elementos: 550\n"
     ]
    }
   ],
   "source": [
    "# Crearé un tensor nuevo para probar estas y mostrar su funcionamiento\n",
    "\n",
    "tensor_agregacion = torch.arange(0, 101, 10)\n",
    "tensor_agregacion\n",
    "\n",
    "print(f\"Minimo: {torch.min(tensor_agregacion)}\")\n",
    "print(f\"Maximo: {torch.max(tensor_agregacion)}\")\n",
    "print(f\"Promedio: {torch.mean(tensor_agregacion.type(torch.float32))}\") # Un lio el mean :)\n",
    "print(f\"Suma de los elementos: {torch.sum(tensor_agregacion)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc20a0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimo: 0\n",
      "Maximo: 100\n",
      "Promedio: 50.0\n",
      "Suma: 550\n"
     ]
    }
   ],
   "source": [
    "# Con otras funciones de tipo estructura.funcion()\n",
    "\n",
    "minimo = tensor_agregacion.min() # Hará uso de una función y deberá ser asignado a una varible para luego ser mostrado\n",
    "maximo = tensor_agregacion.max()\n",
    "promedio = tensor_agregacion.float().mean()\n",
    "suma = tensor_agregacion.sum()\n",
    "\n",
    "print(f\"Minimo: {minimo}\")\n",
    "print(f\"Maximo: {maximo}\")\n",
    "print(f\"Promedio: {promedio}\")\n",
    "print(f\"Suma: {suma}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c058b079",
   "metadata": {},
   "source": [
    "# Encontrando índices de elementos específicos\n",
    "\n",
    "Podemos mediante funciones proporcionadas por pyTorch encontrar valores minimos, maximos, entre otros (tal como se vio) y su índice o posición dentro de este."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "611c2f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemento más chico: 0\n",
      "Elemento más grande: 10\n"
     ]
    }
   ],
   "source": [
    "tensor_max_min = torch.arange(start=0, end=101, step=10)\n",
    "print(f\"Elemento más chico: {tensor_max_min.argmin()}\") # Minimo\n",
    "print(f\"Elemento más grande: {tensor_max_min.argmax()}\") # Maximo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbf9286",
   "metadata": {},
   "source": [
    "# reshape, stacking, squeezing, unsqueezing and permuting\n",
    "\n",
    "*Reshaping* - cambia un tensor de entrada a una forma definida.\n",
    "\n",
    "*View* - devuelve una vista de un tensor de entrada de cierta forma, pero mantiene la misma memoria que el tensor original.\n",
    "\n",
    "*Stacking* - combina múltiples tensores uno encima de otro (vstack) o uno al lado del otro (hstack).\n",
    "\n",
    "*Squeeze* - elimina todas las dimensiones de tamaño 1 de un tensor.\n",
    "\n",
    "*Unsqueeze* - añade una dimensión de tamaño 1 a un tensor objetivo.\n",
    "\n",
    "*Permute* - devuelve una vista de la entrada con las dimensiones permutadas (intercambiadas) de una manera específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "84fe966f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor nueve a uno: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n",
      "Tensor tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Tensor de prueba\n",
    "tensor_prueba = torch.arange(1., 10.)\n",
    "tensor_prueba\n",
    "\n",
    "# Reshape: reordena el tensor\n",
    "tensor_reshepe_nueve_uno = tensor_prueba.reshape(9, 1)\n",
    "print(f\"Tensor nueve a uno: {tensor_reshepe_nueve_uno}\")\n",
    "\n",
    "tensor_reshape_uno_nueve = tensor_prueba.reshape(1, 9)\n",
    "print(f\"Tensor {tensor_reshape_uno_nueve}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "446c2ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor cambiado desde el view: tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# View: cambia la vista del tensor según el orden indicado, pero no lo cambia como tal\n",
    "print(f\"Tensor cambiado desde el view: {tensor_prueba.view(1,9)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b094d1eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3., 4., 5., 6., 7., 8., 9.],\n",
      "        [1., 2., 3., 4., 5., 6., 7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "# Stack\n",
    "tensor_stack = torch.stack([tensor_prueba, tensor_prueba]) \n",
    "print(f\"{tensor_stack}\") # Apila el mismo tensor según dimensiones indicada con dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f81ecfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original: tensor([[[1],\n",
      "         [2],\n",
      "         [3],\n",
      "         [4],\n",
      "         [5]]])\n",
      "\n",
      "Shape tras squeeze: torch.Size([5])\n",
      "tensor([1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "# Squeezing: Quita una dimensión del tensor y ordena estos como si fueran de 1 o 0.\n",
    "\n",
    "# Tensor con shape (1, 5, 1)\n",
    "tensor = torch.tensor([[[1], [2], [3], [4], [5]]])\n",
    "print(f\"Tensor original: {tensor}\")  # torch.Size([1, 5, 1])\n",
    "print(f\"\")\n",
    "# Aplicamos squeeze\n",
    "tensor_squeezed = tensor.squeeze()\n",
    "print(f\"Shape tras squeeze: {tensor_squeezed.shape}\")  # torch.Size([5])\n",
    "print(tensor_squeezed)  # tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f61660f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor original: tensor([1, 2, 4])\n",
      "Tensor unsqueeezing cero: tensor([[1, 2, 4]])\n",
      "Tensor unsqueezing uno: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.],\n",
      "        [5.],\n",
      "        [6.],\n",
      "        [7.],\n",
      "        [8.],\n",
      "        [9.]])\n"
     ]
    }
   ],
   "source": [
    "# Unsqueezing: agrega una dimensión al tensor en donde lo indiquemos\n",
    "\n",
    "tensor_unsqueezing = torch.tensor([1, 2, 4])\n",
    "print(f\"Tensor original: {tensor_unsqueezing}\")\n",
    "\n",
    "tensor_unsqueezing_cero = tensor_unsqueezing.unsqueeze(0)\n",
    "print(f\"Tensor unsqueeezing cero: {tensor_unsqueezing_cero}\")\n",
    "\n",
    "tensor_unsqueezing_uno = tensor_unsqueezing.unsqueeze(1)\n",
    "print(f\"Tensor unsqueezing uno: {tensor_reshepe_nueve_uno}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87b36f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:\n",
      " tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "Forma: torch.Size([2, 3])\n",
      "\n",
      "Permutado:\n",
      " tensor([[1, 4],\n",
      "        [2, 5],\n",
      "        [3, 6]])\n",
      "Nueva forma: torch.Size([3, 2])\n"
     ]
    }
   ],
   "source": [
    "# Permuting tensors: cambia el orden de las dimensiones de un tensor sin modificar los datos sino la forma en la que se lee\n",
    "# Analogo a la matriz transpuesta\n",
    "\n",
    "x = torch.tensor([[1, 2, 3],\n",
    "                  [4, 5, 6]])  # shape: (2, 3)\n",
    "print(\"Original:\\n\", x)\n",
    "print(\"Forma:\", x.shape)  # (2, 3)\n",
    "\n",
    "# Usamos permute para invertir las dimensiones\n",
    "x_permutado = x.permute(1, 0)  # nueva forma: (3, 2)\n",
    "print(\"\\nPermutado:\\n\", x_permutado)\n",
    "print(\"Nueva forma:\", x_permutado.shape)  # (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2ecbd4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor imagen: tensor([[[5.3412e-01, 7.8636e-01, 7.1820e-01],\n",
      "         [4.8367e-01, 5.0565e-01, 1.0550e-01],\n",
      "         [8.2807e-02, 4.4185e-01, 3.6433e-01],\n",
      "         ...,\n",
      "         [2.7581e-01, 9.2777e-01, 4.5533e-01],\n",
      "         [7.8643e-01, 3.4519e-01, 1.5912e-01],\n",
      "         [5.2066e-01, 8.4317e-01, 2.8614e-01]],\n",
      "\n",
      "        [[9.4766e-01, 7.8940e-01, 4.3339e-01],\n",
      "         [1.7717e-01, 8.9380e-01, 5.0248e-01],\n",
      "         [2.3280e-02, 7.5168e-01, 7.0389e-01],\n",
      "         ...,\n",
      "         [4.8822e-01, 2.0989e-01, 5.2245e-01],\n",
      "         [3.2859e-01, 6.8142e-01, 6.4889e-01],\n",
      "         [8.7267e-01, 4.4669e-01, 7.7078e-01]],\n",
      "\n",
      "        [[3.0317e-01, 9.2919e-01, 7.6589e-01],\n",
      "         [5.3940e-01, 3.6331e-01, 2.8141e-01],\n",
      "         [7.3621e-01, 9.3254e-01, 6.6202e-01],\n",
      "         ...,\n",
      "         [5.5458e-01, 4.0727e-01, 5.8102e-01],\n",
      "         [1.9459e-01, 5.0436e-01, 7.0351e-01],\n",
      "         [4.2931e-01, 6.2231e-01, 9.7744e-01]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[4.2359e-01, 3.2365e-01, 4.3393e-01],\n",
      "         [7.2216e-01, 5.7534e-01, 5.9620e-01],\n",
      "         [7.9121e-02, 2.9134e-01, 4.2122e-01],\n",
      "         ...,\n",
      "         [3.1197e-01, 2.1535e-01, 6.9644e-02],\n",
      "         [9.0786e-01, 7.8269e-01, 7.8267e-01],\n",
      "         [4.8994e-03, 4.5039e-01, 2.7922e-01]],\n",
      "\n",
      "        [[7.8960e-01, 8.1398e-01, 5.3197e-01],\n",
      "         [6.1245e-01, 9.1100e-01, 2.7767e-01],\n",
      "         [6.1991e-01, 7.9626e-01, 1.7052e-01],\n",
      "         ...,\n",
      "         [9.4144e-01, 3.2560e-01, 9.3840e-01],\n",
      "         [6.6937e-01, 8.6135e-02, 5.7783e-01],\n",
      "         [9.2417e-01, 7.4178e-01, 9.1952e-04]],\n",
      "\n",
      "        [[7.9806e-01, 2.5163e-01, 7.9434e-01],\n",
      "         [7.0270e-01, 3.8296e-01, 8.5859e-01],\n",
      "         [2.8908e-01, 8.4101e-01, 7.0069e-01],\n",
      "         ...,\n",
      "         [7.5546e-01, 7.8736e-01, 5.7590e-01],\n",
      "         [2.3395e-01, 4.2348e-01, 1.9039e-01],\n",
      "         [2.1667e-01, 9.0314e-01, 6.0011e-01]]])\n",
      "Tensor permutado: tensor([[[5.3412e-01, 4.8367e-01, 8.2807e-02,  ..., 2.7581e-01,\n",
      "          7.8643e-01, 5.2066e-01],\n",
      "         [9.4766e-01, 1.7717e-01, 2.3280e-02,  ..., 4.8822e-01,\n",
      "          3.2859e-01, 8.7267e-01],\n",
      "         [3.0317e-01, 5.3940e-01, 7.3621e-01,  ..., 5.5458e-01,\n",
      "          1.9459e-01, 4.2931e-01],\n",
      "         ...,\n",
      "         [4.2359e-01, 7.2216e-01, 7.9121e-02,  ..., 3.1197e-01,\n",
      "          9.0786e-01, 4.8994e-03],\n",
      "         [7.8960e-01, 6.1245e-01, 6.1991e-01,  ..., 9.4144e-01,\n",
      "          6.6937e-01, 9.2417e-01],\n",
      "         [7.9806e-01, 7.0270e-01, 2.8908e-01,  ..., 7.5546e-01,\n",
      "          2.3395e-01, 2.1667e-01]],\n",
      "\n",
      "        [[7.8636e-01, 5.0565e-01, 4.4185e-01,  ..., 9.2777e-01,\n",
      "          3.4519e-01, 8.4317e-01],\n",
      "         [7.8940e-01, 8.9380e-01, 7.5168e-01,  ..., 2.0989e-01,\n",
      "          6.8142e-01, 4.4669e-01],\n",
      "         [9.2919e-01, 3.6331e-01, 9.3254e-01,  ..., 4.0727e-01,\n",
      "          5.0436e-01, 6.2231e-01],\n",
      "         ...,\n",
      "         [3.2365e-01, 5.7534e-01, 2.9134e-01,  ..., 2.1535e-01,\n",
      "          7.8269e-01, 4.5039e-01],\n",
      "         [8.1398e-01, 9.1100e-01, 7.9626e-01,  ..., 3.2560e-01,\n",
      "          8.6135e-02, 7.4178e-01],\n",
      "         [2.5163e-01, 3.8296e-01, 8.4101e-01,  ..., 7.8736e-01,\n",
      "          4.2348e-01, 9.0314e-01]],\n",
      "\n",
      "        [[7.1820e-01, 1.0550e-01, 3.6433e-01,  ..., 4.5533e-01,\n",
      "          1.5912e-01, 2.8614e-01],\n",
      "         [4.3339e-01, 5.0248e-01, 7.0389e-01,  ..., 5.2245e-01,\n",
      "          6.4889e-01, 7.7078e-01],\n",
      "         [7.6589e-01, 2.8141e-01, 6.6202e-01,  ..., 5.8102e-01,\n",
      "          7.0351e-01, 9.7744e-01],\n",
      "         ...,\n",
      "         [4.3393e-01, 5.9620e-01, 4.2122e-01,  ..., 6.9644e-02,\n",
      "          7.8267e-01, 2.7922e-01],\n",
      "         [5.3197e-01, 2.7767e-01, 1.7052e-01,  ..., 9.3840e-01,\n",
      "          5.7783e-01, 9.1952e-04],\n",
      "         [7.9434e-01, 8.5859e-01, 7.0069e-01,  ..., 5.7590e-01,\n",
      "          1.9039e-01, 6.0011e-01]]])\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo con una foto 225x255x3\n",
    "tensor_imagen = torch.rand(size=(255,255,3))\n",
    "\n",
    "print(f\"Tensor imagen: {tensor_imagen}\")\n",
    "\n",
    "tensor_imagen_permutado = tensor_imagen.permute(2, 0, 1)\n",
    "\n",
    "print(f\"Tensor permutado: {tensor_imagen_permutado}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467e2be6",
   "metadata": {},
   "source": [
    "# Índices con PyTorch\n",
    "\n",
    "Para seleccionar datos de un índice específico debemos trabajar igual que con vectores de numpy\n",
    "Al sumarse más dimensiones deja de ser mecánico y fácil, requiere mucha práctica e inclusive abstracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1a68f7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesnor indices: tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "Primera dimensión --> tensor_indices[0]:\n",
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "Segunda dimensión, primer 'fila' de elementos --> tensor_indices[0][0]:\n",
      "tensor([1, 2, 3])\n",
      "Segunda dimensión, segunda 'fila' de elementos --> tensor_indices[0][1]:\n",
      "tensor([4, 5, 6])\n",
      "Segunda dimensión, tercera 'fila' de elementos --> tensor_indices[0][2]:\n",
      "tensor([7, 8, 9])\n",
      "Elementos específicos -->tensor_indices[dimension][fila][posición]\n",
      "Elemento centra --> tensor_indices[0][1][1]:\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "tensor_indices = torch.arange(1, 10).reshape(1, 3, 3)\n",
    "print(f\"Tesnor indices: {tensor_indices}\")\n",
    "\n",
    "print(f\"Primera dimensión --> tensor_indices[0]:\")\n",
    "print(f\"{tensor_indices[0]}\")\n",
    "print(f\"Segunda dimensión, primer 'fila' de elementos --> tensor_indices[0][0]:\")\n",
    "print(f\"{tensor_indices[0][0]}\")\n",
    "\n",
    "print(f\"Segunda dimensión, segunda 'fila' de elementos --> tensor_indices[0][1]:\")\n",
    "print(f\"{tensor_indices[0][1]}\")\n",
    "\n",
    "print(f\"Segunda dimensión, tercera 'fila' de elementos --> tensor_indices[0][2]:\")\n",
    "print(f\"{tensor_indices[0][2]}\")\n",
    "\n",
    "print(f\"Elementos específicos -->tensor_indices[dimension][fila][posición]\")\n",
    "print(f\"Elemento centra --> tensor_indices[0][1][1]:\")\n",
    "print(f\"{tensor_indices[0][1][1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "65fabb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1, 2, 3],\n",
      "         [4, 5, 6],\n",
      "         [7, 8, 9]]])\n",
      "tensor([6])\n"
     ]
    }
   ],
   "source": [
    "# Podrémos también acceder a todos los elementos hasta determinado elemento con slice \n",
    "\n",
    "print(tensor_indices[:,])\n",
    "print(tensor_indices[:,1,2]) # Y así, hacer muchos para practicar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbce5f8b",
   "metadata": {},
   "source": [
    "# PyTorch y numPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "19b558fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7.], dtype=torch.float64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_array =  np.arange(1.0, 8.0)\n",
    "\n",
    "print(np_array.dtype)\n",
    "\n",
    "\n",
    "tensor = torch.from_numpy(np_array)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f1992634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sumar uno a cada eleento con tensores de numpy\n",
    "\n",
    "np_tensor = np.arange(1.0, 11.0)\n",
    "np_tensor = np_tensor + 1 # con dtype=tipo podrémos cambiar el tipo de vector de np\n",
    "\n",
    "np_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7264b082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_aleatorio_a: \n",
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]])\n",
      "tensor_aleatorio_b: \n",
      "tensor([[0.8694, 0.5677, 0.7411, 0.4294],\n",
      "        [0.8854, 0.5739, 0.2666, 0.6274],\n",
      "        [0.2696, 0.4414, 0.2969, 0.8317]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# Aleatoriedad\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_aleatorio_a = torch.rand(3, 4)\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "tensor_aleatorio_b = torch.rand(3, 4)\n",
    "\n",
    "print(f\"tensor_aleatorio_a: \")\n",
    "print(f\"{tensor_aleatorio_a}\")\n",
    "print(f\"tensor_aleatorio_b: \")\n",
    "print(f\"{tensor_aleatorio_b}\")\n",
    "\n",
    "print(tensor_aleatorio_a == tensor_aleatorio_b )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
